{
  "amd_instinct_gpus": [
    {
      "model": "MI300X",
      "architecture": "CDNA 3",
      "gfxip": "gfx942",
      "release_year": 2023,
      "xcds": 8,
      "compute_units": 304,
      "cus_per_xcd": 38,
      "wavefront_size": 64,
      "base_clock_ghz": 2.1,
      "memory_size_gb": 192,
      "memory_type": "HBM3",
      "memory_stacks": 8,
      "memory_bandwidth_gbps": 5300,
      "l3_cache_mb": 256,
      "l2_cache_mb": 32,
      "l2_per_xcd_mb": 4,
      "l1_vector_kb": 32,
      "lds_per_cu_kb": 64,
      "vgpr_per_cu_kb": 512,
      "sgpr_per_cu_kb": 12.5,
      "fp64_tflops": 163.4,
      "fp32_tflops": 163.4,
      "fp16_tflops": 1307.4,
      "fp8_tflops": 2614.9,
      "int8_tops": 2614.9,
      "tdp_watts": 750,
      "interconnect": "Infinity Fabric",
      "infinity_fabric_links": 7,
      "pcie": "Gen 5 x16",
      "process_node": "5nm/6nm",
      "use_cases": ["AI Training", "AI Inference", "HPC", "Large Language Models"]
    },
    {
      "model": "MI300A",
      "architecture": "CDNA 3 + Zen 4",
      "gfxip": "gfx942",
      "release_year": 2023,
      "xcds": 6,
      "compute_units": 228,
      "cus_per_xcd": 38,
      "wavefront_size": 64,
      "base_clock_ghz": 2.1,
      "memory_size_gb": 128,
      "memory_type": "HBM3",
      "memory_bandwidth_gbps": 5300,
      "l3_cache_mb": 256,
      "l2_cache_mb": 24,
      "l2_per_xcd_mb": 4,
      "l1_vector_kb": 32,
      "lds_per_cu_kb": 64,
      "vgpr_per_cu_kb": 512,
      "sgpr_per_cu_kb": 12.5,
      "fp64_tflops": 122.6,
      "fp32_tflops": 122.6,
      "fp16_tflops": 490.5,
      "cpu_cores": 24,
      "cpu_architecture": "Zen 4",
      "tdp_watts": 550,
      "interconnect": "Infinity Fabric",
      "process_node": "5nm/6nm",
      "use_cases": ["APU Workloads", "AI Training", "HPC", "Unified Memory Applications"]
    },
    {
      "model": "MI250X",
      "architecture": "CDNA 2",
      "gfxip": "gfx90a",
      "release_year": 2021,
      "gcds": 2,
      "compute_units": 220,
      "cus_per_gcd": 110,
      "wavefront_size": 64,
      "base_clock_ghz": 1.7,
      "memory_size_gb": 128,
      "memory_type": "HBM2e",
      "memory_bandwidth_gbps": 3277,
      "l3_cache_mb": 16,
      "l3_per_gcd_mb": 8,
      "l2_cache_mb": 16,
      "lds_per_cu_kb": 64,
      "vgpr_per_cu_kb": 512,
      "accvgpr_per_cu_kb": 512,
      "fp64_tflops": 95.7,
      "fp32_tflops": 47.9,
      "fp16_tflops": 383,
      "int8_tops": 383,
      "tdp_watts": 560,
      "interconnect": "Infinity Fabric",
      "process_node": "6nm",
      "use_cases": ["HPC", "AI Training", "Scientific Computing"]
    },
    {
      "model": "MI250",
      "architecture": "CDNA 2",
      "gfxip": "gfx90a",
      "release_year": 2021,
      "gcds": 2,
      "compute_units": 208,
      "cus_per_gcd": 104,
      "wavefront_size": 64,
      "base_clock_ghz": 1.7,
      "memory_size_gb": 128,
      "memory_type": "HBM2e",
      "memory_bandwidth_gbps": 3277,
      "l3_cache_mb": 16,
      "l3_per_gcd_mb": 8,
      "l2_cache_mb": 16,
      "lds_per_cu_kb": 64,
      "vgpr_per_cu_kb": 512,
      "fp64_tflops": 90.5,
      "fp32_tflops": 45.3,
      "fp16_tflops": 362,
      "tdp_watts": 500,
      "interconnect": "Infinity Fabric",
      "process_node": "6nm",
      "use_cases": ["HPC", "AI Training", "Scientific Computing"]
    },
    {
      "model": "MI210",
      "architecture": "CDNA 2",
      "gfxip": "gfx90a",
      "release_year": 2021,
      "gcds": 1,
      "compute_units": 104,
      "wavefront_size": 64,
      "base_clock_ghz": 1.7,
      "memory_size_gb": 64,
      "memory_type": "HBM2e",
      "memory_bandwidth_gbps": 1638,
      "l3_cache_mb": 8,
      "l2_cache_mb": 8,
      "lds_per_cu_kb": 64,
      "vgpr_per_cu_kb": 512,
      "fp64_tflops": 45.3,
      "fp32_tflops": 22.6,
      "fp16_tflops": 181,
      "int8_tops": 181,
      "tdp_watts": 300,
      "interconnect": "Infinity Fabric",
      "process_node": "6nm",
      "use_cases": ["HPC", "AI Training", "Mainstream Data Center"]
    },
    {
      "model": "MI100",
      "architecture": "CDNA 1",
      "gfxip": "gfx908",
      "release_year": 2020,
      "compute_units": 120,
      "wavefront_size": 64,
      "base_clock_ghz": 1.5,
      "memory_size_gb": 32,
      "memory_type": "HBM2",
      "memory_bandwidth_gbps": 1229,
      "l3_cache_mb": 8,
      "l2_cache_mb": 16,
      "lds_per_cu_kb": 64,
      "vgpr_per_cu_kb": 256,
      "accvgpr_per_cu_kb": 256,
      "fp64_tflops": 11.5,
      "fp32_tflops": 23.1,
      "fp16_tflops": 184.6,
      "int8_tops": 184.6,
      "tdp_watts": 300,
      "interconnect": "Infinity Fabric",
      "process_node": "7nm",
      "use_cases": ["HPC", "AI Training", "Scientific Computing"]
    },
    {
      "model": "MI60",
      "architecture": "Vega 20 (GCN 5.1)",
      "gfxip": "gfx906",
      "release_year": 2018,
      "compute_units": 64,
      "wavefront_size": 64,
      "base_clock_ghz": 1.7,
      "memory_size_gb": 32,
      "memory_type": "HBM2",
      "memory_bandwidth_gbps": 1024,
      "l3_cache_mb": 4,
      "vgpr_per_cu_kb": 256,
      "fp64_tflops": 7.4,
      "fp32_tflops": 14.7,
      "fp16_tflops": 29.5,
      "tdp_watts": 300,
      "process_node": "7nm",
      "use_cases": ["HPC", "Deep Learning", "Rendering"]
    },
    {
      "model": "MI50",
      "architecture": "Vega 20 (GCN 5.1)",
      "gfxip": "gfx906",
      "release_year": 2018,
      "compute_units": 60,
      "wavefront_size": 64,
      "base_clock_ghz": 1.7,
      "memory_size_gb": 16,
      "memory_type": "HBM2",
      "memory_bandwidth_gbps": 1024,
      "l3_cache_mb": 4,
      "vgpr_per_cu_kb": 256,
      "fp64_tflops": 6.7,
      "fp32_tflops": 13.3,
      "fp16_tflops": 26.5,
      "tdp_watts": 300,
      "process_node": "7nm",
      "use_cases": ["HPC", "Deep Learning", "Rendering"]
    }
  ],
  "architectures": {
    "CDNA 3": {
      "focus": "AI and HPC Compute",
      "key_features": [
        "XCD (Accelerator Complex Die) chiplet design",
        "Matrix Core Engines with FP8/TF32 support",
        "HBM3 Support with vertical integration",
        "Advanced Infinity Fabric (7 links per GPU)",
        "4 ACEs (Asynchronous Compute Engines) per XCD",
        "L3 Cache (256 MiB shared)"
      ],
      "generation": "3rd Gen CDNA",
      "year": 2023,
      "performance_vs_cdna2": {
        "fp16_bf16": "3x improvement",
        "int8": "6.8x improvement",
        "fp8_vs_fp32": "16x improvement"
      }
    },
    "CDNA 2": {
      "focus": "HPC and AI Training",
      "key_features": [
        "Matrix Core Engines (AccVGPR)",
        "Dual GCD (Graphics Compute Die) design",
        "Unified Memory Architecture",
        "Infinity Fabric Link",
        "Enhanced FP64 performance",
        "L3 Cache support"
      ],
      "generation": "2nd Gen CDNA",
      "year": 2021
    },
    "CDNA 1": {
      "focus": "HPC Workloads",
      "key_features": [
        "Matrix Core Engines (AccVGPR)",
        "HBM2 Support",
        "Optimized for FP64/FP32",
        "L3 Cache (8 MiB)"
      ],
      "generation": "1st Gen CDNA",
      "year": 2020
    }
  }
}
